---
title: "Regresión Lineal Múltiple - Eliminación bidireccional"
author: "SSPIAII_Equipo4"
date: "2024-02-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Integrantes:<br> 
  1. Gómez Plascencia Waldo.<br>
  2. Ascencio Padilla Isaac Ulises.<br>
  3. Vidrio Lizaola Alfonso Manuel.<br>
  4. Becerra Ramírez Alejandro.<br>
  5. Aceves Díaz César Alejandro.<br>
  
# ¿Qué es la eliminación bidireccional? 
La eliminación bidireccional, también conocida como método “stepwise”, es un procedimiento utilizado en la regresión lineal múltiple para seleccionar automáticamente las variables más significativas para el modelo.<br>
En este método, se introducen todas las variables en la ecuación y luego se van excluyendo una tras otra. Aquella variable que tenga la menor correlación parcial con la variable dependiente será la primera en ser considerada para su eliminación. Si satisface el criterio de eliminación, se eliminará.<br>

# Proceso de selección de variables. 
```{r, echo=FALSE}
proceso <- readLines("proceso_seleccion_variables.R")
load("Grafica")
print(proceso)
plt.Profit.Data
```

# Conclusiones personales. 

#### Gómez Plascencia Waldo.<br> 
Conclusión
La regresión lineal multivariable fue interesante en este caso debido a que 
al finalizar la selección, el modelo solo terminó con variables, me queda la duda de
si hay casos en los que el modelo es mejor con más de dos y el hecho de que aun no
he aprendido a identificar los resultados con base en las graficas generadas me complicada
un poco el terminar de comprender las regresiones lineales, pero de igual manera fue curioso
ver como es la seleción bidireccional.

#### Ascencio Padilla Isaac Ulises.<br> 
Conclusión
La parte más complicada para entender el algoritmo es la parte de la eliminación
hacia delante y hacia atrás porque puede resultar confuso la manera en la que se
debe hacer, ya que se menciona que se debe eliminar la variable con la mayor estadística
de prueba y después la variable con el menor estadístico de prueba hasta llegar al mejor
modelo, y al ser una regresión múltiple, si se considera que el mejor modelo es solo con 
una variable, se convierte en una regresión simple.

#### Becerra Ramírez Alejandro.<br> 
Conclusión
Lo que más se nos generó duda del algoritmo fue al momento de aplicar la función en la que
elimina la variable con mayor estadística de prueba y luego la de menor, ya qué no estabamos
seguro si recorría todo el dataset para poder encontrar el mejor modelo.

#### Vidrio Lizaola Alfonso Manuel.<br> 
Conclusión

#### Aceves Díaz César Alejandro.<br> 
Inicialmente, lo que me confundía era el tema bidireccional puesto que en árboles
esto es completamente diferente partiendo desde el incio y el fin hacia el centro
de este, sin embargo, mis compañeros me ayudaron a entender que se hace una evaluación
del nivel de significancia que tienen las variables para poder determinar cuál es la 
de mejor y cuál es la de peor, para poder eliminar o trabajar con alguna de estas dos 
en las próximas iteraciones.